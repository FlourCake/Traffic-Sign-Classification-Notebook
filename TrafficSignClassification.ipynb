{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Import & Path](#Import-&-Path)\n",
    "* [Dataset Preparation](#Dataset-Preparation)\n",
    "  * [General Configuration](#General-Configuration)\n",
    "    * [Get Classes](#Get-Classes)\n",
    "  * [Collecting Training Data](#Collecting-Training-Data)\n",
    "    * [Shuffling Training Data](#Shuffling-Training-Data)\n",
    "    * [Train Validation Split](#Train-Validation-Split)\n",
    "    * [Encoding the Labels](#Encoding-the-Labels)\n",
    "  * [Set Configuration Variable And Training Data](#Set-Configuration-Variable-And-Training-Data)\n",
    "* [Create and Train Models](#Create-and-Train-Models)\n",
    "    * [Create Model](#Create-Model)\n",
    "        * [Evaluate Model](#Evaluate-Model)\n",
    "    * [Create Pretrain Models](#Create-Pretrain-Models)\n",
    "    * [Train Model](#Train-Model)\n",
    "        * [Train with 64 Batch](#Train-with-64-Batch)\n",
    "            * [0.001 Learning Rate](#0.001-Learning-Rate)\n",
    "            * [0.0001 Learning Rate](#0.0001-Learning-Rate)\n",
    "        * [Train with 32 Batch](#Train-with-32-Batch)\n",
    "            * [0.001 Learning Rate](#0.001-Learning-Rate)\n",
    "            * [0.0001 Learning Rate](#0.0001-Learning-Rate)\n",
    "        * [Train with 16 Batch](#Train-with-16-Batch)\n",
    "            * [0.001 Learning Rate](#0.001-Learning-Rate)\n",
    "            * [0.0001 Learning Rate](#0.0001-Learning-Rate)\n",
    "        * [Train with 8 Batch](#Train-with-8-Batch)\n",
    "            * [0.001 Learning Rate](#0.001-Learning-Rate)\n",
    "            * [0.0001 Learning Rate](#0.0001-Learning-Rate)\n",
    "* [Score](#Score)\n",
    "    * [Load Model List and Evaluate Data](#Load-Model-List-and-Evaluate-Data)\n",
    "        * [Show Model List](#Show-Model-List)\n",
    "    * [Load Test Data](#Load-Test-Data)\n",
    "    * [Create Score Functions](#Create-Score-Functions)\n",
    "    * [Predict Test Data](#Predict-Test-Data)\n",
    "    * [Show Testing Sample](#Show-Testing-Sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Activation, Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()\n",
    "trainPath = os.path.join(os.getcwd(), \"Path/to/TrainImages\")\n",
    "testPath = os.path.join(os.getcwd(), \"Path/to/TestImages\")\n",
    "testPath2 = os.path.join(os.getcwd(), \"Online-Test-sort\")\n",
    "modelPath = os.path.join(os.getcwd(), \"model\")\n",
    "print(trainPath)\n",
    "print(testPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Configuration\n",
    "Set global variable with general conf. The conf mention below:\n",
    "\n",
    "| Image size   |    | Color mode   |    | Epochs |\n",
    "|--------------|----|--------------|----|--------|\n",
    "| 75 x 75 pixel|    |RGB/3 Channels|    | 20     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 75\n",
    "width = 75\n",
    "channels = 3\n",
    "epochs = 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Classes\n",
    "Set total classes and classes label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CATEGORIES = len(os.listdir(trainPath))\n",
    "NUM_CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Overview\n",
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Training Data\n",
    "Collecting and processing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = []\n",
    "image_labels = []\n",
    "\n",
    "trainDir = os.listdir(trainPath)\n",
    "i = 0\n",
    "for dir in trainDir:\n",
    "    path = os.path.join(trainPath, dir)\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    for img in images:\n",
    "        if not img.endswith('.jpg'):\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                image = Image.open(path + '/' +img)\n",
    "                resize_image = image.resize((height, width))\n",
    "                enchanced_image = resize_image.filter(ImageFilter.SHARPEN)\n",
    "                final_image = enchanced_image#.convert('L').convert('RGB')\n",
    "                image_data.append(np.array(final_image))\n",
    "\n",
    "                image_labels.append(i)\n",
    "            except:\n",
    "                print(\"Error in \" + img)\n",
    "                \n",
    "    i = i + 1\n",
    "\n",
    "# Changing the list to numpy array\n",
    "image_data = np.array(image_data)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "print(image_data.shape, image_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indexes = np.arange(image_data.shape[0])\n",
    "np.random.shuffle(shuffle_indexes)\n",
    "image_data = image_data[shuffle_indexes]\n",
    "image_labels = image_labels[shuffle_indexes]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "X_train = X_train/255 \n",
    "X_val = X_val/255\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_valid.shape\", X_val.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"y_valid.shape\", y_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
    "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Configuration Variable And Training Data\n",
    "Set configuration and train valid test datasets with tensorflow\n",
    "\n",
    "Training dataset with several configurations as mention below:\n",
    "\n",
    " - 4 Architecture, 3 Batch Size, 2 Learning Rate\n",
    "\n",
    "| Architecture |    | Batch Size |    | Learning Rate |\n",
    "|--------------|----|------------|----|---------------|\n",
    "| VGG-16       |    | 8          |    | 0.001         |\n",
    "| ResNet-50    |    | 16         |    | 0.0001        |\n",
    "| Inception-V3 |    | 32         |\n",
    "| Xception     |    | 64         |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "Create global model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(pretrain_model, batch_size, learning_rate, name):\n",
    "    aug = ImageDataGenerator()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(pretrain_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=math.pow(10, (learning_rate * -1))), metrics=['accuracy'])\n",
    "    history = model.fit(aug.flow(X_train, y_train, batch_size=batch_size), epochs=epochs, validation_data=(X_val, y_val))\n",
    "    model.save('model/' + name + '.h5')\n",
    "\n",
    "    return history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model\n",
    "Create global model evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateModel(name, history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.savefig('model/' + name + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pretrain Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_vgg16 = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top = False,\n",
    "    input_shape = (height, width, channels),\n",
    "    pooling = 'avg',\n",
    "    classes = 43,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "pretrain_vgg16.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_resnet50 = tf.keras.applications.ResNet50(\n",
    "    include_top = False,\n",
    "    input_shape = (height, width, channels),\n",
    "    pooling = 'avg',\n",
    "    classes = 43,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "pretrain_resnet50.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_inceptionv3 = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top = False,\n",
    "    input_shape = (height, width, channels),\n",
    "    pooling = 'avg',\n",
    "    classes = 43,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "pretrain_inceptionv3.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_xception = tf.keras.applications.xception.Xception(\n",
    "    include_top = False,\n",
    "    input_shape = (height, width, channels),\n",
    "    pooling = 'avg',\n",
    "    classes = 43,\n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "pretrain_xception.trainable = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainProcess(pretrain_model, batch_size, learning_rate, model_name):\n",
    "    name = '{}-{}-{}'.format(model_name, batch_size, learning_rate)\n",
    "    history = TrainModel(pretrain_model, batch_size, learning_rate, name)\n",
    "\n",
    "    with open('./model/' + name + '.pickle', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    EvaluateModel(name, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(batch_size, learning_rate):\n",
    "    TrainProcess(pretrain_vgg16, batch_size, learning_rate, 'vgg16')\n",
    "    TrainProcess(pretrain_resnet50, batch_size, learning_rate, 'resnet50')\n",
    "    TrainProcess(pretrain_inceptionv3, batch_size, learning_rate, 'inceptionv3')\n",
    "    TrainProcess(pretrain_xception, batch_size, learning_rate, 'xception')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with 64 Batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 3\n",
    "\n",
    "Train(batch_size, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 4\n",
    "\n",
    "Train(batch_size, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with 32 Batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 3\n",
    "\n",
    "Train(batch_size, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 4\n",
    "\n",
    "Train(batch_size, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with 16 Batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 3\n",
    "\n",
    "Train(batch_size, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 4\n",
    "\n",
    "Train(batch_size, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with 8 Batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 3\n",
    "\n",
    "Train(batch_size, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 4\n",
    "\n",
    "Train(batch_size, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model List and Evaluate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelList = pd.DataFrame(columns=['model', 'accuracy', 'loss', 'val_accuracy', 'val_loss'])\n",
    "\n",
    "for x in os.listdir('./model'):\n",
    "    if x.endswith('.h5'):\n",
    "        modelList = modelList.append({'model': x.split('.')[0]}, ignore_index=True)\n",
    "    elif x.endswith('.pickle'):\n",
    "        with open('./model/' + x, 'rb') as file_pi:\n",
    "            history = pickle.load(file_pi)\n",
    "            modelList.loc[modelList['model'] == x.replace('.pickle', '.h5'), 'accuracy'] = history['accuracy'][-1]\n",
    "            modelList.loc[modelList['model'] == x.replace('.pickle', '.h5'), 'loss'] = history['loss'][-1]\n",
    "            modelList.loc[modelList['model'] == x.replace('.pickle', '.h5'), 'val_accuracy'] = history['val_accuracy'][-1]\n",
    "            modelList.loc[modelList['model'] == x.replace('.pickle', '.h5'), 'val_loss'] = history['val_loss'][-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Model List\n",
    "Show model list and save to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in modelList['model']:\n",
    "    print(x)\n",
    "\n",
    "print(len(modelList))\n",
    "\n",
    "modelList.to_excel(\"modelList.xlsx\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(data_dir + '/Test.csv')\n",
    "\n",
    "labels = test[\"ClassId\"].values\n",
    "imgs = test[\"Path\"].values\n",
    "\n",
    "data = []\n",
    "\n",
    "for img in imgs:\n",
    "    try:\n",
    "        image = Image.open(data_dir + '/' +img)\n",
    "        resize_image = image.resize((height, width))\n",
    "        enchanced_image = resize_image.filter(ImageFilter.SHARPEN)\n",
    "        data.append(np.array(resize_image))\n",
    "    except:\n",
    "        print(\"Error in \" + img)\n",
    "X_test = np.array(data)\n",
    "X_test = X_test/255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Score Functions\n",
    "Create confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confMatrix(modelName, labels, pred):\n",
    "    cf = confusion_matrix(labels, pred)\n",
    "    plt.clf()\n",
    "    plt.figure(figsize = (20,20))\n",
    "    sns.heatmap(cf, annot=True)\n",
    "    plt.savefig('model/' + modelName + '-confusion-matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationReport(modelName, labels, pred):\n",
    "    cr = classification_report(labels, pred, output_dict=True)\n",
    "\n",
    "    df = pd.DataFrame(cr).transpose()\n",
    "    df.to_excel('model/' + modelName + '-classification-report.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test Data\n",
    "Load model and predict test data, then save to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_accuracy = 0\n",
    "max_accuracy_model = ''\n",
    "max_accuracy_pred = []\n",
    "\n",
    "for x in modelList['model']:\n",
    "    model = keras.models.load_model('model/' + x + '.h5')\n",
    "    \n",
    "    predict_x = model.predict(X_test)\n",
    "    pred = np.argmax(predict_x, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, pred)\n",
    "    print('Test Data accuracy: ', accuracy * 100)\n",
    "\n",
    "    confMatrix(x, labels, pred)\n",
    "    classificationReport(x, labels, pred)\n",
    "\n",
    "    if accuracy > max_accuracy:\n",
    "        max_accuracy = accuracy\n",
    "        max_accuracy_model = x\n",
    "        max_accuracy_pred = pred\n",
    "\n",
    "print('Max accuracy: ', max_accuracy * 100)\n",
    "print('Max accuracy model: ', max_accuracy_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Testing Sample\n",
    "Show testing sample from max accuracy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 25))\n",
    "\n",
    "start_index = 0\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    prediction = max_accuracy_pred[start_index + i]\n",
    "    actual = labels[start_index + i]\n",
    "    col = 'g'\n",
    "    if prediction != actual:\n",
    "        col = 'r'\n",
    "    plt.xlabel('Actual={} || Pred={}'.format(actual, prediction), color = col)\n",
    "    plt.imshow(X_test[start_index + i])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TugasAkhir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
